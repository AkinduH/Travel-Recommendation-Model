{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations, permutations\n",
    "import ast\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_df = pd.read_csv('places_preprocessed.csv')\n",
    "users_df = pd.read_csv('users_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          name\n",
      "0                   Maha Oya Hot Water Springs\n",
      "1                     Jayanthi Wewa Hot Spring\n",
      "2                    Kanniya Hot Water Springs\n",
      "3                     Sinharaja Forest Reserve\n",
      "4                        Pitawala Patana Trail\n",
      "5                  Madunagala Hot Water Spring\n",
      "6                  Horton Plains National Park\n",
      "7                                     Knuckles\n",
      "8                        Crocodile Lake Panama\n",
      "9                         Anawilundawa Wetland\n",
      "10  Sinharaja Rain forest, Waddagala, Kalawana\n",
      "11                                 Panama Wewa\n",
      "12         Piduruthalagala Conservation Forest\n",
      "13                         Bird Watching Tower\n",
      "14                                   rumassala\n"
     ]
    }
   ],
   "source": [
    "def recommend_locations(user_activities, places, user_bucket_list, top_n_per_activity=5):\n",
    "    # Combine all activities into a single string for each place\n",
    "    places['combined_activities'] = places['extracted_activities'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "    \n",
    "    # Create a TF-IDF Vectorizer with lowered max_df and increased min_df\n",
    "    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "    \n",
    "    try:\n",
    "        # Fit and transform the combined activities\n",
    "        tfidf_matrix = vectorizer.fit_transform(places['combined_activities'])\n",
    "        \n",
    "        # Transform the user's preferred activities\n",
    "        user_activities_str = ' '.join(user_activities)\n",
    "        user_tfidf = vectorizer.transform([user_activities_str])\n",
    "        \n",
    "        # Calculate cosine similarities between user activities and place activities\n",
    "        cosine_similarities = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
    "        \n",
    "        # Get the indices of the top_n_per_activity places with the highest similarity scores for each activity\n",
    "        top_indices = set()\n",
    "        for activity in user_activities:\n",
    "            activity_tfidf = vectorizer.transform([activity])\n",
    "            activity_similarities = cosine_similarity(activity_tfidf, tfidf_matrix).flatten()\n",
    "            activity_top_indices = activity_similarities.argsort()[-top_n_per_activity:][::-1]\n",
    "            top_indices.update(activity_top_indices)\n",
    "        \n",
    "        # Convert the set to a sorted list based on overall cosine similarity and keep only the top 15 unique places\n",
    "        top_indices = sorted(top_indices, key=lambda idx: cosine_similarities[idx], reverse=True)[:15]\n",
    "        \n",
    "        # Get the recommended locations\n",
    "        recommended_locations = places.iloc[top_indices].copy()\n",
    "    except ValueError:\n",
    "        # If vectorization fails, return all places without duplicates\n",
    "        print(\"Vectorization failed. Returning all unique places.\")\n",
    "        recommended_locations = places.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    # Add unique places from user's bucket list\n",
    "    for bucket_item in user_bucket_list:\n",
    "        matched_places = places[\n",
    "            (places['name'].str.lower() == bucket_item.lower()) | \n",
    "            (places['formatted_address'].str.lower() == bucket_item.lower())\n",
    "        ]\n",
    "        # Exclude already recommended places\n",
    "        matched_places = matched_places[~matched_places.index.isin(recommended_locations.index)]\n",
    "        if not matched_places.empty:\n",
    "            recommended_locations = pd.concat([recommended_locations, matched_places], ignore_index=True)\n",
    "            # Ensure no duplicates after adding bucket list places\n",
    "            recommended_locations = recommended_locations.drop_duplicates(subset=['name'], keep='first')\n",
    "            # Optionally limit the total number of recommendations\n",
    "            if len(recommended_locations) >= 15:\n",
    "                recommended_locations = recommended_locations.head(15)\n",
    "                break\n",
    "    \n",
    "    return recommended_locations\n",
    "\n",
    "user_activities = users_df.iloc[1]['Preferred Activities'].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "user_activities = [\n",
    "    activity.lower().strip()\n",
    "    .replace('safaris', 'wild life safaris')\n",
    "    .replace('hot air ballooning', 'air ballooning') \n",
    "    for activity in user_activities\n",
    "]\n",
    "user_bucket_list = users_df.iloc[1]['Bucket list destinations Sri Lanka'].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "recommended_locations = recommend_locations(user_activities, places_df, user_bucket_list)\n",
    "print(recommended_locations[['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity: butterfly watching\n",
      "Place: Sinharaja Forest Reserve, Score: 3.0\n",
      "Place: Pitawala Patana Trail, Score: 5.0\n",
      "Place: Horton Plains National Park, Score: 5.0\n",
      "Place: Knuckles, Score: 5.0\n",
      "\n",
      "Activity: hot springs\n",
      "Place: Maha Oya Hot Water Springs, Score: 4.0\n",
      "Place: Jayanthi Wewa Hot Spring, Score: 3.75\n",
      "Place: Kanniya Hot Water Springs, Score: 3.8\n",
      "Place: Madunagala Hot Water Spring, Score: 4.785714285714286\n",
      "\n",
      "Activity: wildlife viewing\n",
      "Place: Sinharaja Forest Reserve, Score: 3.0\n",
      "Place: Pitawala Patana Trail, Score: 4.25\n",
      "Place: Horton Plains National Park, Score: 5.0\n",
      "Place: Knuckles, Score: 4.0\n",
      "Place: Crocodile Lake Panama, Score: 4.5\n",
      "Place: Anawilundawa Wetland, Score: 2.2\n",
      "Place: Sinharaja Rain forest, Waddagala, Kalawana, Score: 3.6\n",
      "Place: Panama Wewa, Score: 4.2\n",
      "Place: Piduruthalagala Conservation Forest, Score: 4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_places_for_each_activity(user_activities, recommended_locations):\n",
    "    activity_places = {activity: [] for activity in user_activities}\n",
    "    \n",
    "    for activity in user_activities:\n",
    "        for index, row in recommended_locations.iterrows():\n",
    "            extracted_activities = row['extracted_activities']\n",
    "            activity_scores = row['activity_scores']\n",
    "            \n",
    "            # Convert string representations to lists if necessary\n",
    "            if isinstance(extracted_activities, str):\n",
    "                extracted_activities = ast.literal_eval(extracted_activities)\n",
    "            if isinstance(activity_scores, str):\n",
    "                activity_scores = ast.literal_eval(activity_scores)\n",
    "            \n",
    "            if activity in extracted_activities:\n",
    "                activity_index = extracted_activities.index(activity)\n",
    "                activity_score = activity_scores[activity_index]\n",
    "                activity_places[activity].append((row['name'], activity_score))\n",
    "    \n",
    "    return activity_places\n",
    "\n",
    "activity_places = get_places_for_each_activity(user_activities, recommended_locations)\n",
    "for activity, places in activity_places.items():\n",
    "    print(f\"Activity: {activity}\")\n",
    "    for place, score in places:\n",
    "        print(f\"Place: {place}, Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Horton Plains National Park\n",
      "Place: Sinharaja Forest Reserve\n",
      "Place: Knuckles\n",
      "Place: Madunagala Hot Water Spring\n",
      "Total Score: 45.643500546986125\n",
      "\n",
      "Set 2:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Horton Plains National Park\n",
      "Place: Knuckles\n",
      "Place: Madunagala Hot Water Spring\n",
      "Place: Crocodile Lake Panama\n",
      "Total Score: 44.12208210392103\n",
      "\n",
      "Set 3:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Horton Plains National Park\n",
      "Place: Knuckles\n",
      "Place: Madunagala Hot Water Spring\n",
      "Place: Panama Wewa\n",
      "Total Score: 43.942999181101555\n",
      "\n",
      "Set 4:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Horton Plains National Park\n",
      "Place: Sinharaja Forest Reserve\n",
      "Place: Knuckles\n",
      "Place: Maha Oya Hot Water Springs\n",
      "Total Score: 43.815265180911176\n",
      "\n",
      "Set 5:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Horton Plains National Park\n",
      "Place: Kanniya Hot Water Springs\n",
      "Place: Sinharaja Forest Reserve\n",
      "Place: Knuckles\n",
      "Total Score: 43.60893958738988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add bucket list destinations to the score calculation\n",
    "def get_top_location_sets_with_bucket_list(activity_places, user_bucket_list, top_n=10):\n",
    "    unique_places = set()\n",
    "    for places in activity_places.values():\n",
    "        for place, score in places:\n",
    "            unique_places.add(place)\n",
    "    \n",
    "    # Generate all possible combinations of 5 locations\n",
    "    all_combinations = list(combinations(unique_places, 5))\n",
    "    \n",
    "    # Filter combinations to ensure each activity is covered\n",
    "    valid_combinations = []\n",
    "    for combo in all_combinations:\n",
    "        activity_counts = []\n",
    "        for activity, places in activity_places.items():\n",
    "            count = sum(1 for place, score in places if place in combo)\n",
    "            activity_counts.append(count)\n",
    "        \n",
    "        # Check if the combination is valid\n",
    "        if 0 not in activity_counts and activity_counts.count(1) < 2:\n",
    "            valid_combinations.append(combo)\n",
    "    \n",
    "    if not valid_combinations:\n",
    "        print(\"No valid combinations found. Consider adjusting the combination size or activity constraints.\")\n",
    "        return []\n",
    "    \n",
    "    # Calculate the sum of activity scores for each valid combination\n",
    "    combo_scores = []\n",
    "    for combo in valid_combinations:\n",
    "        score_sum = 0\n",
    "        for activity, places in activity_places.items():\n",
    "            for place, score in places:\n",
    "                if place in combo:\n",
    "                    score_sum += score\n",
    "        # Add 1 for each location if that location or its formatted_address is in the bucket list\n",
    "        for place in combo:\n",
    "            if place in user_bucket_list or any(place.lower() in address.lower() for address in user_bucket_list):\n",
    "                score_sum += 1\n",
    "        combo_scores.append((combo, score_sum))\n",
    "    \n",
    "    # Sort combinations by the highest sum of activity scores\n",
    "    combo_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top_n combinations\n",
    "    top_combinations = combo_scores[:top_n]\n",
    "    \n",
    "    # Add the rating to the score_sum for the top_n combinations\n",
    "    final_combinations = []\n",
    "    for combo, score_sum in top_combinations:\n",
    "        rating_sum = 0\n",
    "        rating_count = 0\n",
    "        for place in combo:\n",
    "            place_rating = places_df[places_df['name'] == place]['rating'].values\n",
    "            if len(place_rating) > 0 and not pd.isna(place_rating[0]):\n",
    "                rating_sum += place_rating[0]\n",
    "                rating_count += 1\n",
    "        if rating_count > 0:\n",
    "            avg_rating = rating_sum / rating_count\n",
    "            score_sum += avg_rating\n",
    "        final_combinations.append((combo, score_sum))\n",
    "    \n",
    "    # Sort the final combinations by the updated score_sum\n",
    "    final_combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return final_combinations[:top_n]\n",
    "\n",
    "bucket_list = places_df[places_df['name'].isin(user_bucket_list) | places_df['formatted_address'].isin(user_bucket_list)]['name'].tolist()\n",
    "top_location_sets = get_top_location_sets_with_bucket_list(activity_places, bucket_list, top_n=5)\n",
    "if top_location_sets:\n",
    "    for i, (combo, score) in enumerate(top_location_sets):\n",
    "        print(f\"Set {i+1}:\")\n",
    "        for place in combo:\n",
    "            print(f\"Place: {place}\")\n",
    "        print(f\"Total Score: {score}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No top location sets could be generated based on the current criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Knuckles\n",
      "Place: Horton Plains National Park\n",
      "Place: Sinharaja Forest Reserve\n",
      "Place: Madunagala Hot Water Spring\n",
      "Total Score: 45.643500546986125\n",
      "Minimum Travel Distance: 201.30200083388704 km\n",
      "Final Score: 1.0\n",
      "\n",
      "Set 2:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Knuckles\n",
      "Place: Horton Plains National Park\n",
      "Place: Madunagala Hot Water Spring\n",
      "Place: Crocodile Lake Panama\n",
      "Total Score: 44.12208210392103\n",
      "Minimum Travel Distance: 252.63555735298897 km\n",
      "Final Score: 0.24482679350616485\n",
      "\n",
      "Set 3:\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Knuckles\n",
      "Place: Horton Plains National Park\n",
      "Place: Madunagala Hot Water Spring\n",
      "Place: Panama Wewa\n",
      "Total Score: 43.942999181101555\n",
      "Minimum Travel Distance: 251.18540344209 km\n",
      "Final Score: 0.1897585622647221\n",
      "\n",
      "Set 4:\n",
      "Place: Sinharaja Forest Reserve\n",
      "Place: Horton Plains National Park\n",
      "Place: Knuckles\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Maha Oya Hot Water Springs\n",
      "Total Score: 43.815265180911176\n",
      "Minimum Travel Distance: 207.99953712795278 km\n",
      "Final Score: 0.3407542507582951\n",
      "\n",
      "Set 5:\n",
      "Place: Kanniya Hot Water Springs\n",
      "Place: Pitawala Patana Trail\n",
      "Place: Knuckles\n",
      "Place: Horton Plains National Park\n",
      "Place: Sinharaja Forest Reserve\n",
      "Total Score: 43.60893958738988\n",
      "Minimum Travel Distance: 267.7611687780425 km\n",
      "Final Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def calculate_min_travel_distance(places):\n",
    "    min_distance = float('inf')\n",
    "    best_route = None\n",
    "    for perm in permutations(places):\n",
    "        distance = 0\n",
    "        for i in range(len(perm) - 1):\n",
    "            lat1, lon1 = places_df[places_df['name'] == perm[i]][['lat', 'lng']].values[0]\n",
    "            lat2, lon2 = places_df[places_df['name'] == perm[i + 1]][['lat', 'lng']].values[0]\n",
    "            distance += haversine(lat1, lon1, lat2, lon2)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_route = perm\n",
    "    return min_distance, best_route\n",
    "\n",
    "# Normalize the Total Score and Minimum Travel Distance\n",
    "total_scores = [score for _, score in top_location_sets]\n",
    "min_total_score = min(total_scores)\n",
    "max_total_score = max(total_scores)\n",
    "\n",
    "distances = []\n",
    "for combo, _ in top_location_sets:\n",
    "    min_distance, _ = calculate_min_travel_distance(combo)\n",
    "    distances.append(min_distance)\n",
    "min_distance = min(distances)\n",
    "max_distance = max(distances)\n",
    "\n",
    "normalized_scores = [(score - min_total_score) / (max_total_score - min_total_score) for score in total_scores]\n",
    "normalized_distances = [(max_distance - distance) / (max_distance - min_distance) for distance in distances]\n",
    "\n",
    "# Combine the Objectives\n",
    "alpha = 0.7  \n",
    "final_scores = [alpha * norm_score + (1 - alpha) * norm_distance for norm_score, norm_distance in zip(normalized_scores, normalized_distances)]\n",
    "\n",
    "# Compute the Final Score for Each Set\n",
    "for i, ((combo, score), final_score) in enumerate(zip(top_location_sets, final_scores)):\n",
    "    min_distance, best_route = calculate_min_travel_distance(combo)\n",
    "    print(f\"Set {i+1}:\")\n",
    "    for place in best_route:\n",
    "        print(f\"Place: {place}\")\n",
    "    print(f\"Total Score: {score}\")\n",
    "    print(f\"Minimum Travel Distance: {min_distance} km\")\n",
    "    print(f\"Final Score: {final_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "* We normalized the total scores and minimum travel distances for the top location sets.\n",
    "* We combined the objectives of maximizing the total score and minimizing the travel distance using a weighted approach.\n",
    "* We computed the final score for each set of locations by balancing both objectives.\n",
    "* Our final decision was to use an equal weight (alpha = 0.5) for both the total score and the travel distance.\n",
    "* We successfully identified the best route for each set of locations based on the minimum travel distance.\n",
    "* The final model is now ready to recommend locations based on user activities and preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model building and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationRecommender:\n",
    "\n",
    "    def __init__(self, places_df):\n",
    "        if isinstance(places_df, list):\n",
    "            try:\n",
    "                self.places_df = pd.DataFrame(places_df)\n",
    "                print(\"Converted input list to DataFrame.\")\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Failed to convert list to DataFrame: {e}\")\n",
    "        elif isinstance(places_df, pd.DataFrame):\n",
    "            self.places_df = places_df\n",
    "        else:\n",
    "            raise TypeError(\"places_df must be a pandas DataFrame or a list of dictionaries.\")\n",
    "\n",
    "        # Ensure essential columns exist\n",
    "        required_columns = {'name', 'lat', 'lng', 'formatted_address', 'extracted_activities', 'activity_scores', 'rating'}\n",
    "        missing_columns = required_columns - set(self.places_df.columns)\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"The following required columns are missing from places_df: {missing_columns}\")\n",
    "\n",
    "    def recommend_locations(self, user_activities, user_bucket_list, top_n_per_activity=5):\n",
    "        if not isinstance(self.places_df, pd.DataFrame):\n",
    "            raise AttributeError(\"places_df is not a pandas DataFrame.\")\n",
    "        \n",
    "        places = self.places_df.copy()\n",
    "        \n",
    "        if 'extracted_activities' in places.columns:\n",
    "            places['combined_activities'] = places['extracted_activities'].apply(\n",
    "                lambda x: ' '.join(x) if isinstance(x, list) else (' '.join(ast.literal_eval(x)) if isinstance(x, str) else str(x))\n",
    "            )\n",
    "        else:\n",
    "            raise AttributeError(\"'extracted_activities' column is missing from places_df.\")\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "        \n",
    "        try:\n",
    "            tfidf_matrix = vectorizer.fit_transform(places['combined_activities'])\n",
    "            user_activities_str = ' '.join(user_activities)\n",
    "            user_tfidf = vectorizer.transform([user_activities_str])\n",
    "            cosine_similarities = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
    "            \n",
    "            top_indices = set()\n",
    "            for activity in user_activities:\n",
    "                activity_tfidf = vectorizer.transform([activity])\n",
    "                activity_similarities = cosine_similarity(activity_tfidf, tfidf_matrix).flatten()\n",
    "                activity_top_indices = activity_similarities.argsort()[-top_n_per_activity:][::-1]\n",
    "                top_indices.update(activity_top_indices)\n",
    "            \n",
    "            top_indices = sorted(top_indices, key=lambda idx: cosine_similarities[idx], reverse=True)[:15]\n",
    "            recommended_locations = places.iloc[top_indices].copy()\n",
    "        except ValueError as ve:\n",
    "            print(f\"Vectorization failed: {ve}. Returning all unique places.\")\n",
    "            recommended_locations = places.drop_duplicates(subset=['name'])\n",
    "        \n",
    "        for bucket_item in user_bucket_list:\n",
    "            matched_places = places[\n",
    "                (places['name'].str.lower() == bucket_item.lower()) | \n",
    "                (places['formatted_address'].str.lower() == bucket_item.lower())\n",
    "            ]\n",
    "            matched_places = matched_places[~matched_places.index.isin(recommended_locations.index)]\n",
    "            if not matched_places.empty:\n",
    "                recommended_locations = pd.concat([recommended_locations, matched_places], ignore_index=True)\n",
    "                recommended_locations = recommended_locations.drop_duplicates(subset=['name'], keep='first')\n",
    "                if len(recommended_locations) >= 15:\n",
    "                    recommended_locations = recommended_locations.head(15)\n",
    "                    break\n",
    "        \n",
    "        return recommended_locations\n",
    "\n",
    "    def get_places_for_each_activity(self, user_activities, recommended_locations):\n",
    "        activity_places = {activity: [] for activity in user_activities}\n",
    "        \n",
    "        for activity in user_activities:\n",
    "            for index, row in recommended_locations.iterrows():\n",
    "                extracted_activities = row['extracted_activities']\n",
    "                activity_scores = row['activity_scores']\n",
    "                \n",
    "                if isinstance(extracted_activities, str):\n",
    "                    try:\n",
    "                        extracted_activities = ast.literal_eval(extracted_activities)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error parsing extracted_activities for place {row['name']}: {e}\")\n",
    "                        continue\n",
    "                if isinstance(activity_scores, str):\n",
    "                    try:\n",
    "                        activity_scores = ast.literal_eval(activity_scores)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error parsing activity_scores for place {row['name']}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if activity in extracted_activities:\n",
    "                    activity_index = extracted_activities.index(activity)\n",
    "                    if activity_index < len(activity_scores):\n",
    "                        activity_score = activity_scores[activity_index]\n",
    "                        activity_places[activity].append((row['name'], activity_score))\n",
    "                    else:\n",
    "                        print(f\"Activity index out of range for place {row['name']}.\")\n",
    "        \n",
    "        return activity_places\n",
    "\n",
    "    def get_top_location_sets_with_bucket_list(self, activity_places, user_bucket_list, top_n=10):\n",
    "        unique_places = set()\n",
    "        for places in activity_places.values():\n",
    "            for place, score in places:\n",
    "                unique_places.add(place)\n",
    "        \n",
    "        all_combinations = list(combinations(unique_places, 5))\n",
    "        valid_combinations = []\n",
    "        for combo in all_combinations:\n",
    "            activity_counts = []\n",
    "            for activity, places in activity_places.items():\n",
    "                count = sum(1 for place, score in places if place in combo)\n",
    "                activity_counts.append(count)\n",
    "            \n",
    "            if 0 not in activity_counts and activity_counts.count(1) < 2:\n",
    "                valid_combinations.append(combo)\n",
    "        \n",
    "        if not valid_combinations:\n",
    "            print(\"No valid combinations found. Consider adjusting the combination size or activity constraints.\")\n",
    "            return []\n",
    "        \n",
    "        combo_scores = []\n",
    "        for combo in valid_combinations:\n",
    "            score_sum = 0\n",
    "            for activity, places in activity_places.items():\n",
    "                for place, score in places:\n",
    "                    if place in combo:\n",
    "                        score_sum += score\n",
    "            for place in combo:\n",
    "                if place in user_bucket_list or any(place.lower() in address.lower() for address in user_bucket_list):\n",
    "                    score_sum += 1\n",
    "            combo_scores.append((combo, score_sum))\n",
    "        \n",
    "        combo_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_combinations = combo_scores[:top_n]\n",
    "        \n",
    "        final_combinations = []\n",
    "        for combo, score_sum in top_combinations:\n",
    "            rating_sum = 0\n",
    "            rating_count = 0\n",
    "            for place in combo:\n",
    "                place_rating = self.places_df[self.places_df['name'] == place]['rating'].values\n",
    "                if len(place_rating) > 0 and not pd.isna(place_rating[0]):\n",
    "                    rating_sum += place_rating[0]\n",
    "                    rating_count += 1\n",
    "            if rating_count > 0:\n",
    "                avg_rating = rating_sum / rating_count\n",
    "                score_sum += avg_rating\n",
    "            final_combinations.append((combo, score_sum))\n",
    "        \n",
    "        final_combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return final_combinations[:top_n]\n",
    "\n",
    "    @staticmethod\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        R = 6371\n",
    "        dlat = np.radians(lat2 - lat1)\n",
    "        dlon = np.radians(lon2 - lon1)\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "        return R * c\n",
    "\n",
    "    def calculate_min_travel_distance(self, places):\n",
    "        min_distance = float('inf')\n",
    "        best_route = None\n",
    "        for perm in permutations(places):\n",
    "            distance = 0\n",
    "            for i in range(len(perm) - 1):\n",
    "                place1 = self.places_df[self.places_df['name'] == perm[i]]\n",
    "                place2 = self.places_df[self.places_df['name'] == perm[i + 1]]\n",
    "                if place1.empty or place2.empty:\n",
    "                    print(f\"Place not found: {perm[i]} or {perm[i + 1]}\")\n",
    "                    distance = float('inf')\n",
    "                    break\n",
    "                lat1, lon1 = place1[['lat', 'lng']].values[0]\n",
    "                lat2, lon2 = place2[['lat', 'lng']].values[0]\n",
    "                distance += self.haversine(lat1, lon1, lat2, lon2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                best_route = perm\n",
    "        return min_distance, best_route\n",
    "\n",
    "    def recommend_top_places(self, user_activities, user_bucket_list):\n",
    "        user_activities = [\n",
    "            activity.lower().strip()\n",
    "            .replace('safaris', 'wild life safaris')\n",
    "            .replace('hot air ballooning', 'air ballooning') \n",
    "            for activity in user_activities\n",
    "        ]\n",
    "        \n",
    "        recommended_locations = self.recommend_locations(user_activities, user_bucket_list)\n",
    "        activity_places = self.get_places_for_each_activity(user_activities, recommended_locations)\n",
    "        bucket_list = self.places_df[\n",
    "            self.places_df['name'].isin(user_bucket_list) | \n",
    "            self.places_df['formatted_address'].isin(user_bucket_list)\n",
    "        ]['name'].tolist()\n",
    "        top_location_sets = self.get_top_location_sets_with_bucket_list(activity_places, bucket_list, top_n=10)\n",
    "\n",
    "        if not top_location_sets:\n",
    "            print(\"No top location sets found.\")\n",
    "            return []\n",
    "        \n",
    "        total_scores = [score for _, score in top_location_sets]\n",
    "        min_total_score = min(total_scores)\n",
    "        max_total_score = max(total_scores)\n",
    "\n",
    "        distances = []\n",
    "        for combo, _ in top_location_sets:\n",
    "            min_distance, _ = self.calculate_min_travel_distance(combo)\n",
    "            distances.append(min_distance)\n",
    "        min_distance = min(distances)\n",
    "        max_distance = max(distances)\n",
    "\n",
    "        if max_total_score - min_total_score == 0:\n",
    "            normalized_scores = [1 for _ in total_scores]\n",
    "        else:\n",
    "            normalized_scores = [(score - min_total_score) / (max_total_score - min_total_score) for score in total_scores]\n",
    "        \n",
    "        if max_distance - min_distance == 0:\n",
    "            normalized_distances = [1 for _ in distances]\n",
    "        else:\n",
    "            normalized_distances = [(max_distance - distance) / (max_distance - min_distance) for distance in distances]\n",
    "\n",
    "        alpha = 0.7\n",
    "        final_scores = [\n",
    "            alpha * norm_score + (1 - alpha) * norm_distance \n",
    "            for norm_score, norm_distance in zip(normalized_scores, normalized_distances)\n",
    "        ]\n",
    "\n",
    "        if not final_scores:\n",
    "            print(\"No final scores calculated.\")\n",
    "            return []\n",
    "        \n",
    "        max_final_score_index = final_scores.index(max(final_scores))\n",
    "        combo, score = top_location_sets[max_final_score_index]\n",
    "        min_distance, best_route = self.calculate_min_travel_distance(combo)\n",
    "        final_score = final_scores[max_final_score_index]\n",
    "\n",
    "        return best_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = LocationRecommender(places_df)\n",
    "\n",
    "with open('Recommendation Model.pkl', 'wb') as file:\n",
    "    dill.dump(recommender, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Preferred Activities:\n",
      "- cycling\n",
      "- historical monuments\n",
      "- village homestays\n",
      "\n",
      "User Bucket List Destinations in Sri Lanka:\n",
      "- Polonnaruwa\n",
      "- Hatton\n",
      "- Anuradhapura\n",
      "- Ella\n",
      "- Haputale\n",
      "\n",
      "Final recommended places:\n",
      "Place: Velgam Vehera Buddhist Temple\n",
      "Place: Polonnaruwa Ancient City\n",
      "Place: Deegavapi Maha Stupa\n",
      "Place: Udawatta Kele Sanctuary\n",
      "Place: Viharamahadevi Park\n"
     ]
    }
   ],
   "source": [
    "with open('Recommendation Model.pkl', 'rb') as file:\n",
    "    loaded_recommender = dill.load(file)\n",
    "\n",
    "#Enter user number \n",
    "user_number = 0\n",
    "\n",
    "# Example input\n",
    "user_activities = users_df.iloc[user_number]['Preferred Activities'].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "user_bucket_list = users_df.iloc[user_number]['Bucket list destinations Sri Lanka'].strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "\n",
    "print(\"User Preferred Activities:\")\n",
    "for activity in user_activities:\n",
    "    print(f\"- {activity}\")\n",
    "\n",
    "print(\"\\nUser Bucket List Destinations in Sri Lanka:\")\n",
    "for destination in user_bucket_list:\n",
    "    print(f\"- {destination}\")\n",
    "\n",
    "best_route = loaded_recommender.recommend_top_places(user_activities, user_bucket_list)\n",
    "print(f\"\\nFinal recommended places:\")\n",
    "for place in best_route:\n",
    "    print(f\"Place: {place}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
